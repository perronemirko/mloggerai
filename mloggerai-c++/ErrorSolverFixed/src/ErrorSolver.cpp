#include "ErrorSolver.hpp"
#include <iostream>
#include <fstream>
#include <ctime>
#include <filesystem>
#include <cstdlib>
#include <cpr/cpr.h>
#include <nlohmann/json.hpp>

namespace fs = std::filesystem;

ErrorSolver::ErrorSolver(const std::string& model,
                         const std::string& log_file,
                         const std::string& output_language,
                         size_t max_bytes,
                         int backup_count,
                         bool verify_ssl)
    : model_(model), log_file_(log_file), output_language_(output_language),
      max_bytes_(max_bytes), backup_count_(backup_count), verify_ssl_(verify_ssl)
{
    const char* env_url = std::getenv("OPENAI_API_URL");
    const char* env_key = std::getenv("OPENAI_API_KEY");
    const char* env_model = std::getenv("OPENAI_API_MODEL");

    base_url_ = env_url ? env_url : "http://localhost:1234/v1";
    api_key_ = env_key ? env_key : "";
    if (model_.empty() && env_model) {
        model_ = env_model;
    }

    fs::create_directories(fs::path(log_file_).parent_path());
}

void ErrorSolver::log(const std::string& level, const std::string& message) {
    std::string timestamp = current_time();
    std::string log_msg = timestamp + " - " + level + " - " + message;

    std::cout << log_msg << std::endl;

    rotate_logs();

    std::ofstream ofs(log_file_, std::ios::app);
    if (ofs.is_open()) {
        ofs << log_msg << std::endl;
        ofs.close();
    }

    if (level == "ERROR") {
        std::string solution = solve_from_log(message);
        std::string combined = "ðŸ“˜ Soluzione AI: " + solution;
        log("DEBUG", combined);
    }
}

std::string ErrorSolver::current_time() {
    std::time_t t = std::time(nullptr);
    char buf[64];
    std::strftime(buf, sizeof(buf), "%Y-%m-%d %H:%M:%S", std::localtime(&t));
    return buf;
}

std::string ErrorSolver::solve_from_log(const std::string& text) {
    try {
        std::string prompt = "Trova il bug e proponi la soluzione in modo molto conciso. Rispondi sempre in lingua " + output_language_;

        nlohmann::json messages = {
            { {"role", "system"}, {"content", prompt} },
            { {"role", "user"}, {"content", text} }
        };

        nlohmann::json payload = {
            {"model", model_},
            {"temperature", 0.3},
            {"max_tokens", 150},
            {"messages", messages}
        };

        // ðŸ‘‡ Configurazione richiesta con SSL on/off
        cpr::Session session;
        session.SetUrl(cpr::Url{base_url_ + "/chat/completions"});
        session.SetHeader({{"Authorization", "Bearer " + api_key_}, {"Content-Type", "application/json"}});
        session.SetBody(cpr::Body{payload.dump()});

        if (!verify_ssl_) {
            session.SetVerifySsl(false);   // disabilita SSL check
        }

        cpr::Response r = session.Post();

        if (r.error) {
            return "Errore AI (cpr): " + r.error.message;
        }

        if (r.status_code == 200) {
            auto json_resp = nlohmann::json::parse(r.text);
            return json_resp["choices"][0]["message"]["content"].get<std::string>();
        } else {
            return "Errore AI: HTTP " + std::to_string(r.status_code) + " - " + r.text;
        }
    } catch (const std::exception& e) {
        return std::string("Errore AI: ") + e.what();
    }
}

void ErrorSolver::rotate_logs() {
    if (!fs::exists(log_file_)) return;

    size_t file_size = fs::file_size(log_file_);
    if (file_size < max_bytes_) return;

    for (int i = backup_count_ - 1; i >= 0; --i) {
        fs::path old_file = (i == 0) ? log_file_ : log_file_ + "." + std::to_string(i);
        fs::path new_file = log_file_ + "." + std::to_string(i + 1);

        if (fs::exists(old_file)) {
            if (i + 1 > backup_count_) {
                fs::remove(old_file);
            } else {
                fs::rename(old_file, new_file);
            }
        }
    }
}
